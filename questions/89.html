<!DOCTYPE html>
<html>
  <head>
        <title>As demonstrated in research, what is the trick that enables training a 10_000 layer deep neural network?</title>
        <meta name="description" content="initialization">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="I95APMDVpSQihTCPDsjpTPmufzwlpFlkDvd6WO/AURCa1TfUYaNl8zS1EOm3J/rDUbO6aPnCznJ3fj7sz2xXwA==" />
    

    <link rel="stylesheet" media="all" href="../packs/css/application-5184725d.css" data-turbolinks-track="reload" />
    <script src="../packs/js/application-d5fac83c9fc8d3ee256f.js" data-turbolinks-track="reload"></script>
    <link href="https://storage.googleapis.com/aiquizzes/static/favicon.ico" rel="shortcut icon" type="image/x-icon" />
  </head>
  <body class="text-gray-900 antialiased">
    <header class="bg-gray-100">
      <div class="sm:flex sm:justify-between sm:items-center max-w-5xl m-auto">
        <div class="flex sm:block items-center justify-between px-2 py-1">
          <a class="no-underline" href="../index.html"><div class="font-bold text-2xl mt-0"><span class="text-orange-500">ai</span>quizzes
            </div></a>

          <div class="sm:hidden">
            <button id="nav_button" type="button" class="block text-gray-600 focus:text-gray-900 hover:text-gray-900 focus:outline-none">
              <svg class="h-6 w-6 fill-current" viewBox="0 0 24 24">
                <path id="nav_hamburger" fill-rule="evenodd" d="M4 5h16a1 1 0 0 1 0 2H4a1 1 0 1 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2z"/>
                <path id="nav_x" class="hidden" fill-rule="evenodd" d="M18.278 16.864a1 1 0 0 1-1.414 1.414l-4.829-4.828-4.828 4.828a1 1 0 0 1-1.414-1.414l4.828-4.829-4.828-4.828a1 1 0 0 1 1.414-1.414l4.829 4.828 4.828-4.828a1 1 0 1 1 1.414 1.414l-4.828 4.829 4.828 4.828z"/>
              </svg>
            </button>
          </div>
        </div>
        <div class="px-2 pb-2 hidden sm:flex" id="nav_links">
          <a class="block px-2 py-1 font-semibold hover:bg-gray-300 rounded sm:mt-2 sm:ml-2 no-underline" href="../knowledgebase.html">Knowledgebase</a>
        </div>
      </div>
    </header>

    <div class="max-w-xl p-8 mx-auto font-serif text-lg">
      <div class="flex justify-between">
  <div class="uppercase text-xs font-semibold text-gray-600 tracking-wide font-sans mt-0">
    Question 8/10 fast.ai v3 lecture 8
  </div>
</div>


<h1 class="shadow-md p-3">
  As demonstrated in research, what is the trick that enables training a 10_000 layer deep neural network?
</h1>

<p class="uppercase text-xs font-semibold text-gray-600 tracking-wide font-sans mt-6">Answer</p>
<article class="shadow-md p-3">
  initialization
</article>


  <p class="uppercase text-xs font-semibold text-gray-600 tracking-wide font-sans mt-6">Relevant part of lecture</p>
  <div class="embed-responsive aspect-ratio-16/9 flex justify-center mt-1 shadow-md">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/4u8FxNEDUeg?start=5185" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

  </div>

  <p class="uppercase text-xs font-semibold text-gray-600 tracking-wide font-sans mt-6">supplementary material</p>
    <div class="text-sm shadow-md p-3">
      We take things for granted as they are, but there are many recent inventions that make the training of modern architectures possible. They include optimizers, activation functions and batchnorm. But there is a single technique without which training a 10_000 layer deep neural network would not be possible and that would make shallower architectures much harder to train, even with all the other goodies at hand. And that is initialization.<br><br>Links to relevant papers:<br><br><a href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers (a paper introducing both the kaiming initialization and relu!)</a><br><a href="https://arxiv.org/abs/1901.09321">Fixup Initialization (how do you train a 10_000 layer beast?!)</a><br><a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a>
    </div>


    </div>
  </body>
</html>
